{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv7vV0_A3ZUO",
        "outputId": "480ba89e-ca3f-4d06-f951-cdcbdff221d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loading dataset from source: AJGT.xlsx...\n",
            "[INFO] Auto-detected schema: Text='Feed', Target='Sentiment'\n",
            "[INFO] Data loaded successfully. Dimensions: (1800, 2)\n",
            "[INFO] Executing text cleaning pipeline...\n",
            "[INFO] Initializing Naive Bayes Classifier...\n",
            "------------------------------\n",
            "✅ Model Accuracy: 0.8556\n",
            "------------------------------\n",
            "[INFO] Performance Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.86      0.83      0.84       167\n",
            "    Positive       0.85      0.88      0.87       193\n",
            "\n",
            "    accuracy                           0.86       360\n",
            "   macro avg       0.86      0.85      0.85       360\n",
            "weighted avg       0.86      0.86      0.86       360\n",
            "\n",
            "[INFO] Exporting inference results to Saudi_Tweets_Analyzed.csv...\n",
            "[INFO] Process completed successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# --- Configuration ---\n",
        "DATA_PATH = 'AJGT.xlsx'\n",
        "OUTPUT_FILE = 'Saudi_Tweets_Analyzed.csv'\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Cleans and normalizes Arabic text data for NLP tasks.\n",
        "    Removes diacritics, tatweel, punctuation, and non-Arabic characters.\n",
        "    \"\"\"\n",
        "    text = str(text)\n",
        "    # Remove Diacritics\n",
        "    text = re.sub(r'[\\u0617-\\u061A\\u064B-\\u0652]', '', text)\n",
        "    # Remove Tatweel\n",
        "    text = re.sub(r'\\u0640', '', text)\n",
        "    # Normalize Alef\n",
        "    text = re.sub(r'[أإآ]', 'ا', text)\n",
        "    # Filter non-Arabic characters\n",
        "    text = re.sub(r'[a-zA-Z0-9]', '', text)\n",
        "    # Remove Punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    return text.strip()\n",
        "\n",
        "# --- 1. Data Ingestion & Schema validation ---\n",
        "try:\n",
        "    print(f\"[INFO] Loading dataset from source: {DATA_PATH}...\")\n",
        "    df = pd.read_excel(DATA_PATH)\n",
        "\n",
        "    # Auto-detect Text vs Sentiment columns based on content\n",
        "    text_col, sentiment_col = None, None\n",
        "\n",
        "    for col in df.columns:\n",
        "        # Check for Arabic content dominance\n",
        "        sample = df[col].astype(str).str.cat(sep=' ')\n",
        "        if len(re.findall(r'[\\u0600-\\u06FF]', sample)) > 100:\n",
        "            text_col = col\n",
        "        # Check for categorical labels (low cardinality)\n",
        "        elif df[col].nunique() < 10:\n",
        "            sentiment_col = col\n",
        "\n",
        "    if text_col and sentiment_col:\n",
        "        print(f\"[INFO] Auto-detected schema: Text='{text_col}', Target='{sentiment_col}'\")\n",
        "        df = df[[sentiment_col, text_col]]\n",
        "        df.columns = ['Sentiment', 'Text']\n",
        "    else:\n",
        "        # Fallback to last two columns\n",
        "        print(\"[WARN] Schema detection failed. Defaulting to last 2 columns.\")\n",
        "        df = df.iloc[:, -2:]\n",
        "        df.columns = ['Sentiment', 'Text']\n",
        "\n",
        "    print(f\"[INFO] Data loaded successfully. Dimensions: {df.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"[ERROR] Source file '{DATA_PATH}' not found.\")\n",
        "    exit()\n",
        "\n",
        "# --- 2. Preprocessing Pipeline ---\n",
        "print(\"[INFO] Executing text cleaning pipeline...\")\n",
        "df['Clean_Text'] = df['Text'].apply(preprocess_text)\n",
        "# Remove empty rows after cleaning\n",
        "df = df[df['Clean_Text'].str.strip() != '']\n",
        "\n",
        "# --- 3. Model Training ---\n",
        "print(\"[INFO] Initializing Naive Bayes Classifier...\")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000)),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['Clean_Text'],\n",
        "    df['Sentiment'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# --- 4. Evaluation ---\n",
        "y_pred = pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"-\" * 30)\n",
        "print(f\"✅ Model Accuracy: {accuracy:.4f}\")\n",
        "print(\"-\" * 30)\n",
        "print(\"[INFO] Performance Metrics:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# --- 5. Deployment Export ---\n",
        "print(f\"[INFO] Exporting inference results to {OUTPUT_FILE}...\")\n",
        "df['Predicted_Sentiment'] = pipeline.predict(df['Clean_Text'])\n",
        "df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
        "print(\"[INFO] Process completed successfully.\")"
      ]
    }
  ]
}